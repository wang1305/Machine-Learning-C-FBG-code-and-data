{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26fd37-1eb7-4180-bddf-c9e1affcce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.optim as optim  # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "from torch.nn.parameter import Parameter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#from pyDOE import lhs         #Latin Hypercube Sampling\n",
    "import scipy.io\n",
    "\n",
    "from smt.sampling_methods import LHS\n",
    "from scipy.io import savemat\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#Set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "#PyTorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda': \n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec246c-2841-486d-a0d7-7031b32d7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './Training and Testing Data/'\n",
    "list_of_files = ['3p0v.tdms','3p5v.tdms','4p0v.tdms','4p5v.tdms','5p0v.tdms','5p5v.tdms','6p0v.tdms','Thermal Cyc.tdms','Distance Cyc 4rotation.tdms','reference for all.tdms','1p5v.tdms','2p0v.tdms','2p5v.tdms']\n",
    "shift_val = [80,90,80,85,86,84,88,80,80,0,81,86,81]\n",
    "\n",
    "X_end_ref = np.array(pd.read_csv('END-REFLECTION.tdms.csv',delimiter=\",\",header = None))\n",
    "X_end_ref = np.mean(X_end_ref,axis = 0)\n",
    "\n",
    "X = []\n",
    "\n",
    "i =0 \n",
    "for label in list_of_files: \n",
    "    X_temp = np.array(pd.read_csv(label +'.csv',header = None))\n",
    "    X_temp = X_temp#/X_end_ref\n",
    "    X.append(X_temp[15+shift_val[i]:2015+shift_val[i]])\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551d02b-b9ea-4e38-8faa-12989052d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_list = ['./3p0v_r/','./3p5v_r/','./4p0v_r/','./4p5v_r/','./5p0v_r/','./5p5v_r/','./6p0v_r/','./Thermal Cyc 5.5 to 0 to 5.5_r/','./Distance Cyc 4 rotation_r/','./reference_r/','./1p5v_r/','./2p0v_r/','./2p5v_r/']\n",
    "Y = []\n",
    "for dir_name in dir_name_list:\n",
    "    list_of_files = sorted(filter(os.path.isfile, glob.glob(dir_name + '*')))\n",
    "\n",
    "    Y_temp = np.zeros((len(list_of_files),480))\n",
    "    i = 0\n",
    "    for file in list_of_files:\n",
    "        Y_temp[i,:] = np.array(pd.read_csv(dir_name+'file_'+'%04d'%i+'.csv',sep=',',header = 0))[:,2]\n",
    "        i = i+1\n",
    "    print(dir_name)\n",
    "    \n",
    "    Y.append(Y_temp[:2000,:])\n",
    "    # Y.append(Y_temp[:2000,188:292])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91822d6a-577f-427e-8991-20e190c912de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X[0] = np.vstack((X[0][:115],X[0][171:1216],X[0][1275:]))#3.0\n",
    "Y[0] = np.vstack((Y[0][:115],Y[0][171:1216],Y[0][1275:]))\n",
    "\n",
    "X[1] = np.vstack((X[1][:168],X[1][225:1270],X[1][1327:]))#3.5\n",
    "Y[1] = np.vstack((Y[1][:168],Y[1][225:1270],Y[1][1327:]))\n",
    "\n",
    "\n",
    "X[2] = np.vstack((X[2][:171],X[2][228:1270],X[2][1327:]))#4.0\n",
    "Y[2] = np.vstack((Y[2][:171],Y[2][228:1270],Y[2][1327:]))\n",
    "\n",
    "\n",
    "X[3] = np.vstack((X[3][:117],X[3][174:1217],X[3][1277:]))# 4.5\n",
    "Y[3] = np.vstack((Y[3][:117],Y[3][174:1217],Y[3][1277:]))\n",
    "\n",
    "\n",
    "X[4] = np.vstack((X[4][:169],X[4][225:1464],X[4][1526:]))#5.0\n",
    "Y[4] = np.vstack((Y[4][:169],Y[4][225:1464],Y[4][1526:]))\n",
    "\n",
    "\n",
    "X[5] = np.vstack((X[5][:120],X[5][175:1220],X[5][1276:]))#5.5\n",
    "Y[5] = np.vstack((Y[5][:120],Y[5][175:1220],Y[5][1276:]))\n",
    "\n",
    "\n",
    "X[6] = np.vstack((X[6][:124],X[6][179:1225],X[6][1280:]))#6.0\n",
    "Y[6] = np.vstack((Y[6][:124],Y[6][179:1225],Y[6][1280:]))\n",
    "\n",
    "X[7] = np.vstack((X[7][:167],X[7][225:1369],X[7][1427:])) #Thermal Cycle\n",
    "Y[7] = np.vstack((Y[7][:167],Y[7][225:1369],Y[7][1427:]))\n",
    "\n",
    "X[8] = np.vstack((X[8][:166],X[8][224:1767],X[8][1823:]))#Distance Cycle\n",
    "Y[8] = np.vstack((Y[8][:166],Y[8][224:1767],Y[8][1823:]))\n",
    "\n",
    "X[10] = np.vstack((X[10][:169],X[10][225:1369],X[10][1428:]))#1.5\n",
    "Y[10] = np.vstack((Y[10][:169],Y[10][225:1369],Y[10][1428:]))\n",
    "\n",
    "X[11] = np.vstack((X[11][:120],X[11][176:1220],X[11][1278:]))#2.0\n",
    "Y[11] = np.vstack((Y[11][:120],Y[11][176:1220],Y[11][1278:]))\n",
    "\n",
    "X[12] = np.vstack((X[12][:120],X[12][175:1220],X[12][1276:]))#2.5\n",
    "Y[12] = np.vstack((Y[12][:120],Y[12][175:1220],Y[12][1276:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c833aec-75e6-4c9c-a001-fb2f07aec05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X[0]\n",
    "Y_full = Y[0]\n",
    "\n",
    "\n",
    "for i in range(1,len(X)):\n",
    "    X_full = np.vstack((X_full,X[i]))\n",
    "    Y_full = np.vstack((Y_full,Y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c58a4f-d8d7-4ca2-8fc0-59ad00dda2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = torch.tensor(X_full,device = device,dtype = torch.float)\n",
    "Y_full = torch.tensor(Y_full,device = device,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22658a-c54e-481d-a4cb-ee3efe78a66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = torch.mean(X_full, axis = 0)\n",
    "X_std = torch.std(X_full, axis = 0)\n",
    "X_full = (X_full - X_mean)/X_std\n",
    "\n",
    "Y_mean = torch.mean(Y_full, axis = 0)\n",
    "Y_std = torch.std(Y_full, axis = 0)\n",
    "Y_full = (Y_full - Y_mean)/Y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57372f9e-65f4-4300-b1c8-38bf8e4f2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.0001, random_state=1)\n",
    "train_size = X_full.shape[0]\n",
    "batches = 50\n",
    "\n",
    "batch_size = int(train_size/batches)\n",
    "\n",
    "x_train_full = []\n",
    "y_train_full = []\n",
    "\n",
    "for b in range(batches):\n",
    "    start = b*batch_size\n",
    "    end = b*batch_size + batch_size\n",
    "    x_train_full.append(X_full[start:end])\n",
    "    y_train_full.append(Y_full[start:end])\n",
    "    \n",
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37061b37-e85d-41be-afb6-705e0d300fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__() #call __init__ from parent class \n",
    "              \n",
    "    \n",
    "        #self.activation = nn.Tanh()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.loss_function = nn.MSELoss(reduction ='mean')\n",
    "        \n",
    "        'Initialise neural network as a list using nn.Modulelist'  \n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        \n",
    "        # std = gain * sqrt(2/(input_dim+output_dim))\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data) \n",
    "\n",
    "    'forward pass'\n",
    "    def forward(self,x):\n",
    "        if torch.is_tensor(x) != True:         \n",
    "            x = torch.from_numpy(x)                \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        for i in range(len(layers)-2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "            \n",
    "        a = self.linears[-1](a) \n",
    "         \n",
    "        return a\n",
    "                    \n",
    "    def loss(self,x_train,y_train):\n",
    "\n",
    "        loss1 = self.loss_function(self.forward(x_train), y_train)\n",
    "        \n",
    "        return loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2863bacd-0aa4-45a9-9061-9b8a03eef482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(seed,x_train,y_train):\n",
    "    \n",
    "    optimizer.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "    loss = NN.loss(x_train,y_train)\n",
    "    loss.backward() #backprop\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b2433-b3d3-4396-beb2-8b4d4a4710c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(max_iter,rep, batches): \n",
    "    print(rep) \n",
    "    torch.manual_seed(rep*11)\n",
    "    start_time = time.time() \n",
    "    thresh_flag = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        for b in range(batches):\n",
    "            x_train = x_train_full[b]\n",
    "            y_train = y_train_full[b]\n",
    "            loss_np = train_step(9*i+6*b,x_train,y_train).cpu().detach().numpy()\n",
    "            #loss_val = NN.loss(X_val,Y_val).cpu().detach().numpy()\n",
    "        if(i%100==0):\n",
    "            print(i,\"Train Loss\",loss_np)#\" Validation Loss:\",loss_val)\n",
    "        train_loss_history.append(loss_np)\n",
    "    \n",
    "    print(i,\"Train Loss\",loss_np)#\" Validation Loss:\",loss_val)\n",
    "    elapsed_time[rep] = time.time() - start_time  \n",
    "    print('Training time: %.2f' % (elapsed_time[rep]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3795d-d2ec-4cfa-ac75-6a09a4445c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_reps = 1\n",
    "max_iter = 5000\n",
    "\n",
    "train_loss_full = []\n",
    "test_mse_full = []\n",
    "test_re_full = []\n",
    "\n",
    "elapsed_time= np.zeros((max_reps,1))\n",
    "time_threshold = np.empty((max_reps,1))\n",
    "time_threshold[:] = np.nan\n",
    "epoch_threshold = max_iter*np.ones((max_reps,1))\n",
    "\n",
    "train_loss_history = []\n",
    "for reps in range(max_reps):  \n",
    "   \n",
    "    train_loss = []\n",
    "    test_mse_loss = []\n",
    "\n",
    "    torch.manual_seed(reps*36)\n",
    "\n",
    "    layers = np.array([800,700,600,500,480])\n",
    "\n",
    "    NN = Sequentialmodel(layers)\n",
    "    \n",
    "    NN.to(device)\n",
    "\n",
    "    \n",
    "    print(NN)\n",
    "\n",
    "    params = list(NN.parameters())\n",
    "\n",
    "    optimizer = torch.optim.SGD(NN.parameters(), lr=8e-2)\n",
    "\n",
    "\n",
    "    train_model(max_iter,reps,batches)\n",
    "    torch.save(NN.state_dict(),'Full_data_final_Jan9_'+str(int(time.time()))+'.pt')\n",
    "    train_loss_full.append(train_loss)\n",
    "    test_mse_full.append(test_mse_loss)\n",
    "    \n",
    "    print('Training time: %.2f' % (elapsed_time[reps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b74760-bfad-452d-a580-ee20f40a5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './Training and Testing Data/'\n",
    "\n",
    "list_of_files = ['5p3v.tdms']\n",
    "\n",
    "shift_val = [84]\n",
    "\n",
    "X_test = []\n",
    "\n",
    "i =0\n",
    "\n",
    "for label in list_of_files: \n",
    "    X_temp = np.array(pd.read_csv(label +'.csv',header = None))\n",
    "    X_temp = (X_temp)#/(X_end_ref)\n",
    "    X_test.append(X_temp[15+shift_val[i]:2015+shift_val[i]])\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0983c-6092-4b07-802d-a8fcccbc2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name_list = ['./5p3v_r/']\n",
    "Y_test = []\n",
    "for dir_name in dir_name_list:\n",
    "    list_of_files = sorted(filter(os.path.isfile, glob.glob(dir_name + '*')))\n",
    "\n",
    "    Y_temp = np.zeros((len(list_of_files),480))\n",
    "    i = 0\n",
    "    for file in list_of_files:\n",
    "        Y_temp[i,:] = np.array(pd.read_csv(dir_name+'file_'+'%04d'%i+'.csv',sep=',',header = 0))[:,2]\n",
    "        i = i+1\n",
    "    print(dir_name)\n",
    "    \n",
    "    Y_test.append(Y_temp[:2000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d572385-ad22-41e0-a550-eecfa4e3ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = np.array([800,700,600,500,480])\n",
    "NN = Sequentialmodel(layers)\n",
    "    \n",
    "NN.to(device)\n",
    "NN.load_state_dict(torch.load('Full_data_final_Jan9_1673315453.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d1276-9ae1-4049-a336-5226249fcaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_test = X_test[0]\n",
    "Y_full_test = Y_test[0]\n",
    "\n",
    "\n",
    "for i in range(1,len(X_test)):\n",
    "    X_full_test = np.vstack((X_full_test,X_test[i]))\n",
    "    Y_full_test = np.vstack((Y_full_test,Y_test[i]))\n",
    "    \n",
    "X_full_test = torch.tensor(X_full_test,device = device,dtype = torch.float)\n",
    "Y_full_test = torch.tensor(Y_full_test,device = device,dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1a12d-6193-4d56-a133-5363cf2e1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_test = (X_full_test - X_mean)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958f1c2-5b5d-444b-a655-7af90b8ff77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_full = np.zeros((2000,480))\n",
    "for i in range(2000):\n",
    "    Y_pred_full[i,:]= (NN.forward(X_full_test[i,:])*Y_std + Y_mean).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff9ab4-96a0-4688-afff-28c0296803d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(Y_pred_full,cmap = 'jet',interpolation='none',extent=[0,13.824,2000,0],aspect = 0.0144,vmin = 0,vmax = 800)\n",
    "\n",
    "ax.set_xticks(np.linspace(0,480*28.8/1000,4), minor=False)\n",
    "ax.tick_params(axis = 'both',bottom = True, top = False, labelbottom = True,labeltop = False,direction = 'out',labelsize = 8)\n",
    "ax.set_xlabel('Location ($mm$)',fontsize = 10)\n",
    "ax.set_ylabel('Time ($ms$)',fontsize = 10)\n",
    "ax.xaxis.set_label_position('bottom') \n",
    "ax.set_title('5.3V Case Predicted',fontweight = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337cf18d-0ce6-46b8-8667-f95c9dff5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.subplots(1,1)\n",
    "    Y_pred_test= (NN.forward(X_full_test[200*i,:])*Y_std + Y_mean).cpu().detach().numpy()\n",
    "    Y_true_test = Y_full_test[200*i,:].cpu().detach().numpy()\n",
    "    plt.plot(188*np.ones(2,),[0,800],'m--')\n",
    "    plt.plot(292*np.ones(2,),[0,800],'m--')\n",
    "    plt.plot(Y_pred_test,'b',label = 'Predicted')\n",
    "    plt.plot(Y_true_test,'r',label = 'True')\n",
    "    plt.xlabel('x',fontsize =18)\n",
    "    plt.ylabel('T',fontsize =18)\n",
    "    plt.title('Frame'+str(200*i))\n",
    "    plt.xlim([0,480])\n",
    "    plt.ylim([0,800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a095d-8a7f-4a7b-ac26-b590e67db761",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_test = 400\n",
    "max_test = 1600\n",
    "iou = np.zeros((max_test - min_test,1))\n",
    "\n",
    "for k in range(min_test,max_test):\n",
    "    i = k-min_test\n",
    "    Y_pred_val= (NN.forward(X_full_test[k,:])*Y_std + Y_mean).cpu().detach().numpy()\n",
    "    Y_true_val = Y_full_test[k,:].cpu().detach().numpy()\n",
    "    \n",
    "    iou_1 = np.sum(np.maximum(Y_pred_val,Y_true_val))\n",
    "    iou_2 = np.sum(np.minimum(Y_pred_val,Y_true_val))\n",
    "    \n",
    "    iou[i] = iou_2/iou_1\n",
    "    \n",
    "print('IOU : ',np.mean(iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53da51-e939-49f8-857a-3f6e3b52ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revision Modification Jan 2024\n",
    "mean_ae= np.zeros((max_test - min_test,1))\n",
    "for k in range(min_test,max_test):\n",
    "    i = k-min_test\n",
    "    Y_pred_val= (NN.forward(X_full_test[k,:])*Y_std + Y_mean).cpu().detach().numpy()\n",
    "    Y_true_val = Y_full_test[k,:].cpu().detach().numpy()\n",
    "    \n",
    "    # iou_1 = np.sum(np.maximum(Y_pred_val,Y_true_val))\n",
    "    # iou_2 = np.sum(np.minimum(Y_pred_val,Y_true_val))\n",
    "    mean_ae[i] = np.mean(np.abs(Y_pred_val-Y_true_val)) \n",
    "    \n",
    "    # iou[i] = iou_2/iou_1\n",
    "    \n",
    "print('Max AE : ',np.max(mean_ae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d637c-c8b0-44d6-9ece-be03d71e6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_test = 400\n",
    "max_test = 1600\n",
    "iou = np.zeros((max_test - min_test,1))\n",
    "\n",
    "for k in range(min_test,max_test):\n",
    "    i = k-min_test\n",
    "    Y_pred_val= (NN.forward(X_full_test[k,:])*Y_std + Y_mean).cpu().detach().numpy()\n",
    "    Y_true_val = Y_full_test[k,:].cpu().detach().numpy()\n",
    "    \n",
    "    iou_1 = np.sum(np.maximum(Y_pred_val[188:292],Y_true_val[188:292]))\n",
    "    iou_2 = np.sum(np.minimum(Y_pred_val[188:292],Y_true_val[188:292]))\n",
    "    \n",
    "    iou[i] = iou_2/iou_1\n",
    "    \n",
    "print('IOU : ',np.mean(iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3c289-1899-4d53-bfe9-70720d396e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_test = 400\n",
    "max_test = 1600\n",
    "mean_ae= np.zeros((max_test - min_test,1))\n",
    "\n",
    "for k in range(min_test,max_test):\n",
    "    i = k-min_test\n",
    "    Y_pred_val= (NN.forward(X_full_test[k,:])*Y_std + Y_mean).cpu().detach().numpy()\n",
    "    Y_true_val = Y_full_test[k,:].cpu().detach().numpy()\n",
    "    \n",
    "    # iou_1 = np.sum(np.maximum(Y_pred_val[188:292],Y_true_val[188:292]))\n",
    "    # iou_2 = np.sum(np.minimum(Y_pred_val[188:292],Y_true_val[188:292]))\n",
    "    mean_ae[i] = np.mean(np.abs(Y_pred_val[188:292]-Y_true_val[188:292])) \n",
    "    \n",
    "    # iou[i] = iou_2/iou_1\n",
    "    \n",
    "print('Max AE : ',np.max(mean_ae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec91bf-1dbc-4287-8c6d-10b8d583a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for k in range(min_test,max_test):\n",
    "    c = c + np.corrcoef(NN.forward(X_full_test[k,:]).cpu().detach().numpy(),Y_full_test[k,:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec8dba-7318-4393-8211-1761ea72653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_corr = []\n",
    "Y_true_corr  = []\n",
    "for k in range(min_test,max_test):\n",
    "    Y_pred_val= Y_pred_corr.append((NN.forward(X_full_test[k,:])*Y_std + Y_mean).cpu().detach().numpy())\n",
    "    Y_true_val = Y_true_corr.append(Y_full_test[k,:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e945d-91cf-4700-b845-ec3e880ae50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_corr = np.array(Y_pred_corr).reshape(-1,1)\n",
    "Y_true_corr = np.array(Y_true_corr).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2350fc3-5b02-485f-b382-da66adc4026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(low=0, high=57600, size=(5760,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14112efe-9f14-4a44-a766-114159bc0194",
   "metadata": {},
   "outputs": [],
   "source": [
    " np.corrcoef(Y_pred_corr[idx].reshape(-1,),Y_true_corr[idx].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49455268-4423-4ea4-9815-c3b0ee556297",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true_corr[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d318ae46-40a7-4228-ad48-e3ed47127f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './XXXX/'\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(Y_pred_corr[idx],Y_true_corr[idx],'r*',markersize = 1,label = 'Data Points')\n",
    "ax.plot([0,800],[0,800],'k',label = 'Ideal Reference')\n",
    "ax.set_xlim([0,800])\n",
    "ax.set_ylim([0,800])\n",
    "\n",
    "ax.set_xlabel('Predicted Temperature ($^\\circ$$C$)',fontsize = 10)\n",
    "ax.set_ylabel('Actual Temperature ($^\\circ$$C$)',fontsize = 10)\n",
    "ax.set_aspect(aspect = 0.9)\n",
    "ax.text(400,300,'Correlation = 0.994')\n",
    "\n",
    "ax.set_title('Correlation Plot')\n",
    "ax.legend()\n",
    "plt.savefig(folder+'5p3v_correlation.png',format = 'png',pad_inches=0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271abb47-4f64-4a9e-bfd3-2b8a5fab1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = ['170-800-200.tdms']\n",
    "\n",
    "X_test = []\n",
    "\n",
    "i =0\n",
    "\n",
    "for label in list_of_files: \n",
    "    X_temp = np.array(pd.read_csv(label +'_smooth_lr21.csv',header = None))\n",
    "    X_ref = np.mean(X_temp[:400],axis =0)\n",
    "    X_temp = 1.5*X_temp#/X_end_ref\n",
    "    i = i+1\n",
    "    \n",
    "X_temp = torch.tensor(X_temp,device = device,dtype = torch.float)\n",
    "X_temp = (X_temp - X_mean)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33127e2d-69fb-4169-ba34-be02e9a23086",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = np.zeros((9000,480))\n",
    "for i in range(9000):\n",
    "    Y_pred_test[i,:]= (NN.forward(X_temp[i,:])*Y_std + Y_mean).cpu().detach().numpy()\n",
    "Y_pred_mean = np.mean(Y_pred_test[:200,:],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb9dd7-7e14-402e-903f-68c8e35fd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Y_250 = NN.forward(X_temp[250,:])*Y_std + Y_mean\n",
    "# for i in range(20):\n",
    "#     plt.subplots(1,1)\n",
    "#     idx = 1500+100*i\n",
    "#     Y_pred_test= (NN.forward(X_temp[idx,:])*Y_std + Y_mean ).cpu().detach().numpy() - Y_pred_mean + 27\n",
    "#     plt.plot(188*np.ones(2,),[0,800],'m--')\n",
    "#     plt.plot(292*np.ones(2,),[0,800],'m--')\n",
    "#     plt.plot(Y_pred_test,'b',label = 'Predicted')\n",
    "#     plt.xlabel('x',fontsize =18)\n",
    "#     plt.ylabel('T',fontsize =18)\n",
    "#     plt.title('Frame'+str(idx))\n",
    "#     plt.xlim([0,480])\n",
    "#     plt.ylim([0,800])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
